/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/external/ms_deformable_attention/functions/deform_attn_func.py:21: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd(cast_inputs=torch.float32)
/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/external/ms_deformable_attention/functions/deform_attn_func.py:38: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
xFormers not available
xFormers not available
[rank: 0] Seed set to 0
/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python panoptic_label_generator/semantic_fine_tuning.py fit ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

Detected pretrain size: 518x518
[ENCODER] Using encoder: ViTCoMeR
Collect Cityscapes frames [train]:   0%|          | 0/2975 [00:00<?, ?it/s]Collect Cityscapes frames [train]:   8%|▊         | 225/2975 [00:00<00:01, 2222.11it/s]Collect Cityscapes frames [train]:  15%|█▌        | 449/2975 [00:00<00:01, 2227.40it/s]Collect Cityscapes frames [train]:  23%|██▎       | 681/2975 [00:00<00:01, 2266.56it/s]Collect Cityscapes frames [train]:  31%|███       | 908/2975 [00:00<00:00, 2258.71it/s]Collect Cityscapes frames [train]:  38%|███▊      | 1142/2975 [00:00<00:00, 2287.06it/s]Collect Cityscapes frames [train]:  46%|████▌     | 1371/2975 [00:00<00:00, 2184.16it/s]Collect Cityscapes frames [train]:  53%|█████▎    | 1591/2975 [00:00<00:00, 2164.96it/s]Collect Cityscapes frames [train]:  61%|██████    | 1809/2975 [00:00<00:00, 2135.93it/s]Collect Cityscapes frames [train]:  68%|██████▊   | 2023/2975 [00:00<00:00, 2045.66it/s]Collect Cityscapes frames [train]:  76%|███████▌  | 2263/2975 [00:01<00:00, 2147.19it/s]Collect Cityscapes frames [train]:  84%|████████▍ | 2497/2975 [00:01<00:00, 2202.71it/s]Collect Cityscapes frames [train]:  92%|█████████▏| 2739/2975 [00:01<00:00, 2265.52it/s]Collect Cityscapes frames [train]: 100%|██████████| 2975/2975 [00:01<00:00, 2291.03it/s]Collect Cityscapes frames [train]: 100%|██████████| 2975/2975 [00:01<00:00, 2216.82it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name    | Type       | Params | Mode 
-----------------------------------------------
0 | encoder | ViTCoMer   | 140 M  | train
1 | head    | Sequential | 1.1 M  | train
-----------------------------------------------
55.5 M    Trainable params
86.6 M    Non-trainable params
142 M     Total params
568.253   Total estimated model params size (MB)
594       Modules in train mode
0         Modules in eval mode
/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/10 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] /work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Input image shape: torch.Size([1, 3, 448, 896])
Before deform_inputs: torch.Size([1, 3, 448, 896])
Before SPM: torch.Size([1, 3, 448, 896])
After SPM - c1: torch.Size([1, 768, 112, 224]), c2: torch.Size([1, 6272, 768]), c3: torch.Size([1, 1568, 768]), c4: torch.Size([1, 392, 768])
Concatenated CNN features shape: torch.Size([1, 8232, 768])
Before patch embedding: torch.Size([1, 3, 448, 896])
After patch embedding: torch.Size([1, 2048, 768])
Extracted dimensions - bs: 1, n: 2048, dim: 768
Grid dimensions - H_vit: 32, W_vit: 64
Patch verification - expected: 2048, actual: 2048
Adapter dimensions - H_adapter: 28, W_adapter: 56
Position embed shape: torch.Size([1, 2048, 768])
After adding position embedding: torch.Size([1, 2048, 768])
Starting interaction loops...
Interaction 0 - Input vit_features: torch.Size([1, 2048, 768]), c: torch.Size([1, 8232, 768])
Before concat - x: torch.Size([1, 2048, 768]), c_select2: torch.Size([1, 1568, 768])
Dimension mismatch: c_select2=1568, x=2048. Interpolating...
After interpolation - c_select2: torch.Size([1, 2048, 768])
[rank0]: Traceback (most recent call last):
[rank0]:   File "panoptic_label_generator/semantic_fine_tuning.py", line 298, in <module>
[rank0]:     cli = SemanticFineTunerCLI()
[rank0]:   File "panoptic_label_generator/semantic_fine_tuning.py", line 287, in __init__
[rank0]:     super().__init__(
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/cli.py", line 394, in __init__
[rank0]:     self._run_subcommand(self.subcommand)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/cli.py", line 701, in _run_subcommand
[rank0]:     fn(**fn_kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/core/module.py", line 1306, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank0]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/optim/adam.py", line 205, in step
[rank0]:     loss = closure()
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 389, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 640, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 633, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "panoptic_label_generator/semantic_fine_tuning.py", line 152, in training_step
[rank0]:     pred = self(rgb)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "panoptic_label_generator/semantic_fine_tuning.py", line 115, in forward
[rank0]:     x = self.forward_encoder(x)  # (B, feat_dim, H, W)
[rank0]:   File "/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/fine_tuning.py", line 73, in forward_encoder
[rank0]:     f1, f2, f3, f4 = self.encoder.forward(img)
[rank0]:   File "/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/models/vit_comer/vit_comer.py", line 200, in forward
[rank0]:     vit_features, c = layer(vit_features, c, self.blocks[indexes[0]:indexes[-1] + 1],
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/models/vit_comer/comer_modules.py", line 438, in forward
[rank0]:     x = self.cti_tov(query=x, reference_points=deform_inputs[0],
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/models/vit_comer/comer_modules.py", line 365, in forward
[rank0]:     query = _inner_forward(query, feat, H, W)
[rank0]:   File "/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/models/vit_comer/comer_modules.py", line 349, in _inner_forward
[rank0]:     c1 = self.attn(self.query_norm(feat), reference_points,
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/minconda3/envs/spino/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/work/dlclarge2/kumars-spino/SPINO_2/panoptic_label_generator/external/ms_deformable_attention/modules/deform_attn.py", line 106, in forward
[rank0]:     assert (input_spatial_shapes[:, 0] *
[rank0]: AssertionError
